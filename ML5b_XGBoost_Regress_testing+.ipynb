{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dca23171-0e41-41ca-a2d3-3def8cb2cd66",
   "metadata": {},
   "source": [
    "Authors: L. Biermann (UoP)\n",
    "Credits: This code was originally developed for the MaRS Modules.\n",
    "License: This code is offered as free-to-use in the public domain, with no warranty.\n",
    "Date_V2: 25/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb9eb-2368-460a-9c90-cd738bbfc23c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.6em; font-weight: bold; padding: 10px; margin: 10px 0; text-align: center;\">\n",
    "    \n",
    "    XGBoost model training -- Round 2\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff73e0-8237-4087-81ba-8e4e3bb4e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Data Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "#ignorewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7afd-8af2-44ea-9afe-5c2861b63ecc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Data Preprocessing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560a835-a995-4b9b-af90-8f954b37c4a9",
   "metadata": {},
   "source": [
    "### Load CSV files containing variables -- pandas' `read_csv function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fa81a-211a-48ff-ba71-bc709239ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are imported in Dataframe format\n",
    "SSH = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSH.csv\", comment='#') # tells pandas to ignore lines starting with '#'\n",
    "SST = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SST.csv\", comment='#')\n",
    "SSS = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSs.csv\", comment='#')\n",
    "VEL = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_VEL.csv\", comment='#')\n",
    "MLD = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_MLD.csv\", comment='#')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7228a4b0-1eb5-4bc2-84f5-9bc2fcea53f7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.1em; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "\n",
    "    Conspicuously missing from our training thus far has been TIME. \n",
    "    We're now going to include Month and Year to see if this improves the accuracy of our SST predictions.    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67e03a-dad7-41e3-9de3-6e5c17a3bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UTC format that our dates (times) are currently in:\n",
    "SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "\n",
    "# Step1: convert to a more friendly format, add 'dates' as new column \n",
    "SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Step2: Remove the times in this case as they contain no real information\n",
    "SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "# Step3: Drop the now unnecessary 'time' column\n",
    "SSH = SSH.drop(columns=['time'])\n",
    "\n",
    "# Extract months+ years (integers)\n",
    "SSH['mo'] = SSH['dates'].dt.month\n",
    "SSH['yr'] = SSH['dates'].dt.year\n",
    "\n",
    "# Re-order columns so that 'dates' is first, followed by 'mo' (month), and then 'zos' (SSH values)\n",
    "SSH = SSH[['dates', 'mo', 'yr', 'zos']]\n",
    "\n",
    "# Display the first 2 rows of the resulting DataFrame\n",
    "print(SSH.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50eacc-7968-49b8-869a-b5c0c113f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now combine these different vars to make a new df\n",
    "df = pd.DataFrame({'Date':SSH['dates'], 'Month':SSH['mo'], 'Year':SSH['yr'], 'SSH':SSH['zos'], 'SST':SST['thetao'], \n",
    "                   'SSS':SSS['so'],'Vuo':VEL['uo'], 'Vvo':VEL['vo'], 'MLD':MLD['mlotst']})\n",
    "print(df.head(3))\n",
    "print(':')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee1a7b-6f4b-4688-856e-d95cdd0b726a",
   "metadata": {},
   "source": [
    "### Set the `predictor` and `target` variables (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786007cb-4a98-495d-a374-2d1b0e3f9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Month', 'Year', 'SSH', 'SSS', 'Vuo', 'Vvo', 'MLD'] # Predictor vars\n",
    "X = df[predictors].values \n",
    "y = df['SST'].values      # Target variable\n",
    "# Needs to be (n,n)(n,)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42294e7-ec41-4844-ae43-df3800780f12",
   "metadata": {},
   "source": [
    "### Split the data into two sets: `training` (80%) and `test` (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916045c-ba64-4fb2-a1a3-39c085fc725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your dataset so 20% is set aside for testing (0.2) \n",
    "# Set random_state to ensure yr train-test split is always the same (for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the 80% training: 20% testing split\n",
    "print(\"Trainin set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\",  X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b02411-1c1d-4046-a946-c67ec4de1c43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.5em; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    \n",
    "    Hyperparameter Tuning\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b527f3b-02e9-4c13-bb39-fc30ffa7e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parameter grid (dictionary) with lists of possible values for each hyperparameter:\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],       # Step size shrinkage used to prevent overfitting\n",
    "    'max_depth': [3, 5, 7],                        # Maximum depth of a tree, controlling model complexity\n",
    "    'min_child_weight': [1, 3, 5],                 # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],             # Fraction of samples to use for each tree\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],      # Fraction of features to consider for each tree\n",
    "    'n_estimators': [100, 200, 300],               # Number of trees (boosting rounds) to build\n",
    "    'gamma': [0, 0.1, 0.5]                         # Minimum loss reduction required to make a split\n",
    "}\n",
    "\n",
    "# Initialise XGBoost regressor model with squared error objective.\n",
    "xgb_reg = xgb.XGBRegressor(objective = 'reg:squarederror', random_state = 42)\n",
    "\n",
    "# Set up RandomizedSearchCV with the following parameters:\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb_reg,                          # The base model to optimize (our XGBoost regressor)\n",
    "    param_distributions=param_grid,               # Dictionary with parameters to sample from (our grid)\n",
    "    n_iter = 100,                                 # Number of random parameter combinations to try (reduces total fits)\n",
    "    scoring='r2',                                 # Metric to evaluate performance (R² in this case)\n",
    "    cv = 5,                                       # Number of cross-validation folds (5-fold cross-validation)\n",
    "    verbose= 1,                                   # Verbosity level to print progress messages during the search\n",
    "    n_jobs =-1,                                   # Use all available CPU cores to parallelize the search\n",
    "    random_state = 42                             # Random seed for reproducibility of the random sampling\n",
    ")\n",
    "\n",
    "# Fit the randomised search on the training data:\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and cross-validation (CV) scores\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best CV R²: {:.2f}\".format(random_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c4c5e-66da-4243-8151-562b97476f37",
   "metadata": {},
   "source": [
    "### Yes! From `R²`= 0.71 to `R²`= 0.96. We can now save this 'even better' model using `save_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddaaddf-e993-4261-9020-6ecc277e168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a JSON file\n",
    "random_search.best_estimator_.save_model(\"xgb_sst_model2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47eddb-27b8-4b44-befe-604a86da037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SHAP to explain our model predictions with XGBoost\n",
    "explainer = shap.TreeExplainer(random_search.best_estimator_)  # Use best_estimator_ from random_search\n",
    "shap_vals = explainer.shap_values(X_test)                      # Compute SHAP values for your test data\n",
    "\n",
    "# Compute the mean absolute SHAP values for each feature\n",
    "# This provides a robust measure of feature importance\n",
    "shap_importance = np.abs(shap_vals).mean(axis = 0)\n",
    "\n",
    "# Create df of the features and their importance (SHAP)\n",
    "shap_df = pd.DataFrame({\n",
    "    \"Variable\": predictors,\n",
    "    \"Mean Absolute SHAP\": shap_importance})\n",
    "\n",
    "# Sort shap_df so the most important features (variables) are at the top:\n",
    "shap_df.sort_values(by = \"Mean Absolute SHAP\", ascending = False, inplace = True)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e75ad-caa4-4c20-832d-0b16142c93a9",
   "metadata": {},
   "source": [
    "### Clearly, `Month` is an incredibly important feature, and `Year` is moderately important for predicting SST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37692a9-b8ff-4b77-b6d2-0b806c547f23",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.6em; font-weight: bold; padding: 10px; margin: 10px 0; text-align: center;\">\n",
    "\n",
    "    XGBoost model deployment -- Round 2\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208d2c5-ae11-46a6-8ccc-7cc16219b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are imported in Dataframe format\n",
    "SSH = pd.read_csv(\"cmems_mod_glo_phy_zos_0.083deg_P1D-m.csv\", comment='#') # tells pandas to ignore lines starting with '#'\n",
    "SST = pd.read_csv(\"cmems_mod_glo_phy-sst_0.083deg_P1D-m.csv\", comment='#')\n",
    "SSS = pd.read_csv(\"cmems_mod_glo_phy-sss_0.083deg_P1D-m.csv\", comment='#')\n",
    "VEL = pd.read_csv(\"cmems_mod_glo_phy-vel_0.083deg_P1D-m.csv\", comment='#')\n",
    "MLD = pd.read_csv(\"cmems_mod_glo_phy_mld_0.083deg_P1D-m.csv\", comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287e1da-49ec-405f-bb5b-bf978f86117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UTC format that our dates (times) are currently in:\n",
    "SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "\n",
    "# Step1: convert to a more friendly format, add 'dates' as new column \n",
    "SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Step2: Remove the times in this case as they contain no real information\n",
    "SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "# Step3: Drop the now unnecessary 'time' column\n",
    "SSH = SSH.drop(columns=['time'])\n",
    "\n",
    "# Extract months+ years (integers)\n",
    "SSH['mo'] = SSH['dates'].dt.month\n",
    "SSH['yr'] = SSH['dates'].dt.year\n",
    "\n",
    "# Re-order columns so that 'dates' is first, followed by 'mo' (month), and then 'zos' (SSH values)\n",
    "SSH = SSH[['dates', 'mo', 'yr', 'zos']]\n",
    "\n",
    "# Combine vars in new df:\n",
    "new_df = pd.DataFrame({'Date':SSH['dates'], 'Month':SSH['mo'], 'Year':SSH['yr'], 'SSH':SSH['zos'], 'SST':SST['thetao'], \n",
    "                       'SSS':SSS['so'], 'Vuo':VEL['uo'], 'Vvo':VEL['vo'], 'MLD':MLD['mlotst']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4038f8-3270-488f-bc33-12135ae6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Month', 'Year', 'SSH', 'SSS', 'Vuo', 'Vvo', 'MLD'] # Predictor vars\n",
    "X_new = new_df[predictors].values     # Features\n",
    "y_new = new_df['SST'].values          # True SST values\n",
    "# Check reshaped data (n,n)(n,)\n",
    "print(X_new.shape, y_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d81888-cfcb-45ea-9f6b-69ec9c46d886",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.5em; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    \n",
    "    Even-Better Model\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c033211-b1d2-433a-9e93-e5bad8637117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_model = xgb.XGBRegressor()               # Create new XGBoost regressor\n",
    "sst_model.load_model(\"xgb_sst_model2.json\")  # Load the model saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e77d13-bc87-4994-976c-ece6c6252026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved XGBoost model: predict 'new' SST\n",
    "sst_pred = sst_model.predict(X_new)\n",
    "\n",
    "# Evaluate model performance on new data:\n",
    "new_r2 = r2_score(y_new, sst_pred)\n",
    "new_rmse = np.sqrt(mean_squared_error(y_new, sst_pred))\n",
    "\n",
    "print(\"New R²:   {:.2f}\".format(new_r2))\n",
    "print(\"New RMSE: {:.2f}\".format(new_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818be2b-429b-4605-b342-be4ab55a128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig1, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "# Plot True and Predicted SSTs\n",
    "ax.plot(new_df['Date'], new_df['SST'], linestyle = '-', c = 'blue', linewidth = 1.0, label = 'True SSTs')\n",
    "ax.plot(new_df['Date'], sst_pred,linestyle = '-.', c = 'orangered', linewidth = 1.5, label = 'Predicted')\n",
    "\n",
    "# Formatting\n",
    "ax.grid(True, color = 'silver', linestyle = ':', linewidth = 0.5)\n",
    "ax.set_xlim([np.nanmin(new_df['Date']), np.nanmax(new_df['Date'])])\n",
    "ax.set_ylabel('SST °C', fontsize = 10, weight = 'bold')\n",
    "ax.legend();\n",
    "\n",
    "# Set the x-axis major locator to every 3 months\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 1))\n",
    "# Format the x-axis ticks as 'mm-yy'\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%y'))\n",
    "# Rotate tick labels for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation = 40, ha = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686c2d5-c561-4593-b471-dda93ae64e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
