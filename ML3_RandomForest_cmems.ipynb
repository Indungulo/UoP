{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dca23171-0e41-41ca-a2d3-3def8cb2cd66",
   "metadata": {},
   "source": [
    "Authors: L. Biermann (UoP)\n",
    "Credits: This code was originally developed for the MaRS Modules.\n",
    "License: This code is offered as free-to-use in the public domain, with no warranty.\n",
    "Date_V2: 25/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb9eb-2368-460a-9c90-cd738bbfc23c",
   "metadata": {},
   "source": [
    "# Shallow Machine Learning Models: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be4359-7113-44df-9db4-33eefaa5d8bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.1em; padding: 10px; margin: 10px 0; text-align: center;\">\n",
    "    \n",
    "    Random forest is an *ensemble* learning method that builds and aggregates multiple decision trees to capture\n",
    "    complex nonlinear relationships in data.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395d4ad-9eff-4dba-9ac7-c07b9dc4d6a8",
   "metadata": {},
   "source": [
    "### Import Libraries including from `sklearn` for shallow ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff73e0-8237-4087-81ba-8e4e3bb4e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import shap\n",
    "\n",
    "# Data Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignorewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7afd-8af2-44ea-9afe-5c2861b63ecc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Data Preprocessing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560a835-a995-4b9b-af90-8f954b37c4a9",
   "metadata": {},
   "source": [
    "### Option 1 to Load CSV files containing variables -- pandas' `read_csv function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fa81a-211a-48ff-ba71-bc709239ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are imported in Dataframe format\n",
    "SSH = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSH.csv\", comment='#') # tells pandas to ignore lines starting with '#'\n",
    "SST = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SST.csv\", comment='#')\n",
    "SSS = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSs.csv\", comment='#')\n",
    "VEL = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_VEL.csv\", comment='#')\n",
    "MLD = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_MLD.csv\", comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67e03a-dad7-41e3-9de3-6e5c17a3bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UTC format that our dates (times) are currently in:\n",
    "SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "\n",
    "# Step1: convert to a more friendly format, add 'dates' as new column \n",
    "SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Step2: Remove the times in this case as they contain no real information\n",
    "SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "# Step3: Drop the now unnecessary 'time' column\n",
    "SSH = SSH.drop(columns=['time'])\n",
    "\n",
    "# Re-order your columns so date is still first\n",
    "SSH = SSH[['dates','zos']]\n",
    "# Display\n",
    "print(SSH.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50eacc-7968-49b8-869a-b5c0c113f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now combine these different vars to make a new df\n",
    "df = pd.DataFrame({'Date':SSH['dates'], 'SSH':SSH['zos'], 'SST':SST['thetao'], 'SSS':SSS['so'], \n",
    "                   'Vuo':VEL['uo'], 'Vvo':VEL['vo'], 'MLD':MLD['mlotst']})\n",
    "print(df.head(3))\n",
    "print(':')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdadede-b0f2-4bca-a587-aa10e18980fc",
   "metadata": {},
   "source": [
    "### Option 2 to Load CSV files containing variables -- `glob` and pandas' `read_csv function`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e71a1b77-92e6-4232-96a0-12c53c2a4550",
   "metadata": {},
   "source": [
    "Though more complicated, it is an easier way to load data if you have loads of files/ filenames change routinely"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92e43d2-5573-4e10-bcc5-0af5c9da5266",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the file pattern to match relevant CSV files\n",
    "file_pattern = \"cmems_mod_glo_phy_my_0.083deg_P1D-m_*.csv\"\n",
    "\n",
    "# Read all matching CSV files into a dictionary\n",
    "df_dict = {}\n",
    "for file in glob.glob(file_pattern):\n",
    "    var_name = file.split(\"_\")[-1].split(\".\")[0]  # Extract variable name from filename\n",
    "    df_dict[var_name] = pd.read_csv(file, comment='#')\n",
    "\n",
    "# Ensure SSH is processed correctly (dates + renaming 'zos' to 'SSH')\n",
    "SSH = df_dict.get(\"SSH\")\n",
    "if SSH is not None:\n",
    "    SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "    SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "    SSH = SSH.drop(columns=['time'])\n",
    "    SSH = SSH.rename(columns={'zos': 'SSH'})  # Rename 'zos' to 'SSH'\n",
    "    SSH = SSH[['dates', 'SSH']]  # Keep 'dates' and SSH variable\n",
    "\n",
    "# Mapping of expected variables to their corresponding column names in CSVs\n",
    "data_vars = {\n",
    "    \"SST\": \"thetao\",\n",
    "    \"SSS\": \"so\",\n",
    "    \"Vuo\": \"uo\",\n",
    "    \"Vvo\": \"vo\",\n",
    "    \"MLD\": \"mlotst\"}\n",
    "\n",
    "# Merge all datasets dynamically\n",
    "df = SSH.copy() if SSH is not None else pd.DataFrame()\n",
    "\n",
    "for key, col in data_vars.items():\n",
    "    dataset_key = \"VEL\" if key in [\"Vuo\", \"Vvo\"] else key  # Ensure velocity data is accessed correctly\n",
    "    if dataset_key in df_dict:\n",
    "        df[key] = df_dict[dataset_key][col].values  # Assign values from each dataset\n",
    "\n",
    "# Print the first few rows to verify the result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee1a7b-6f4b-4688-856e-d95cdd0b726a",
   "metadata": {},
   "source": [
    "### Set the `predictor` and `target` variables (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786007cb-4a98-495d-a374-2d1b0e3f9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SSH', 'SSS', 'Vuo', 'Vvo', 'MLD'] # Predictor vars\n",
    "X = df[predictors].values \n",
    "y = df['SST'].values      # Target variable\n",
    "# Needs to be (n,n)(n,)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42294e7-ec41-4844-ae43-df3800780f12",
   "metadata": {},
   "source": [
    "### Split the data into two sets: `training` (80%) and `test` (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916045c-ba64-4fb2-a1a3-39c085fc725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your dataset so 20% is set aside for testing (0.2) \n",
    "# Set random_state to ensure yr train-test split is always the same (for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the 80% training: 20% testing split\n",
    "print(\"Trainin set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\",  X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b02411-1c1d-4046-a946-c67ec4de1c43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    \n",
    "    Random Forest (tree-based) Model\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a875b-b87b-43f2-a4b4-58f80998b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Train Random Forest Model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators = 100,  # Number of trees in the forest\n",
    "    max_depth = None,    # Trees grow until all leaves are pure (default behavior)\n",
    "    random_state = 42,   # Ensures reproducibility\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f90075-4123-4843-98c2-bb8103de40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict SST on the test dataset\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e04ae2-d25a-4dc5-9f74-8b88e466fea3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Evaluating Model Performance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a9b1b-a97b-4794-8832-dfb9f6d3e2a3",
   "metadata": {},
   "source": [
    "### Metrics for Random Forest Model: `R2` and `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c6c37-b951-43ef-be20-98d5c5a27d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RF Model Performance\n",
    "r2 = r2_score(y_test, y_pred)            # R² score (goodness of fit)\n",
    "mse= mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
    "\n",
    "print(f\"Random Forest R² : {r2:.2f}\")\n",
    "print(f\"Random Forest MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "727a6e44-cfa8-4657-8a86-27c366af4cd0",
   "metadata": {},
   "source": [
    "Multivar Elastic Net R²:   0.59\n",
    "Multivar Elastic Net RMSE: 1.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f0c44-b69f-4913-b7d8-994056b5d8ef",
   "metadata": {},
   "source": [
    "### Better scores again! Do we seem the same feature contributions now that elastic net penalties aren't being applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d7990-09f2-4af5-bc74-27004fa6bd4e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Feature Importance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcf74d-6e09-44c7-9bfe-48f1fd1776e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SHAP to explain our model predications\n",
    "explainer = shap.TreeExplainer(rf_model )    # Explain model predictions\n",
    "shap_vals = explainer.shap_values(X_test)    # Compute SHAP values for test data\n",
    "\n",
    "# Compare Feature Importances from RF\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=predictors)\n",
    "# Create DataFrame (df) to hold the feature names and their RF importance:\n",
    "rf_df = pd.DataFrame({\n",
    "    \"Variables\": predictors,\n",
    "    \"RF Importance\": rf_importance})\n",
    "\n",
    "# Sort rf_df so most important variables are at the top (descending order)\n",
    "rf_df.sort_values(by = \"RF Importance\", ascending = False, inplace = True)\n",
    "print(rf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90811d9c-8681-4750-b731-d9ba2a64b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean absolute SHAP values for each feature\n",
    "# This provides a robust measure of feature importance\n",
    "shap_importance = np.abs(shap_vals).mean(axis = 0)\n",
    "\n",
    "# Create a DataFrame to hold the feature names and their SHAP importance\n",
    "shap_df = pd.DataFrame({\n",
    "    \"Variables\": predictors,\n",
    "    \"Mean Absolute SHAP\": shap_importance})\n",
    "\n",
    "# Sort the DataFrame so that the most important features are at the top\n",
    "shap_df.sort_values(by=\"Mean Absolute SHAP\", ascending=False, inplace=True)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ae97f-49ae-42c9-acfe-fb2e298870a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting SHAP:\n",
    "# Use the diverging \"Spectral\" palette for colormap:\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap = True)\n",
    "\n",
    "# Compute normalized ranking for each feature (btwn 0 - 1)\n",
    "# Note -- shap_df values used to determine relative order:\n",
    "norm_ranks = shap_df[\"Mean Absolute SHAP\"].rank(pct = True)\n",
    "\n",
    "# Map each normalized rank to a colour via colourmap:\n",
    "colors = norm_ranks.apply(lambda x: cmap(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de01517-2fd4-4f45-b32f-cd4dbee82be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "# ----- Plot RF Feature Importance -----\n",
    "sns.barplot(data = rf_df, x = \"RF Importance\", y = \"Variables\", ax = axes[0],\n",
    "    palette = colors)\n",
    "axes[0].set_title( \"RF Variable Importance\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"RF Importance\", fontsize = 10)\n",
    "axes[0].set_ylabel(\"Features\", fontsize = 10)\n",
    "axes[0].grid(axis = 'x', linestyle = '--', alpha = 0.7)\n",
    "\n",
    "# ----- Plot SHAP Feature Importance -----\n",
    "sns.barplot(data = shap_df, x = \"Mean Absolute SHAP\", y = \"Variables\", ax=axes[1],\n",
    "    palette = colors)\n",
    "axes[1].set_title( \"SHAP Variable Importance\", fontweight ='bold')\n",
    "axes[1].set_xlabel(\"Mean Absolute SHAP Value\", fontsize = 10)\n",
    "axes[1].set_ylabel(\"\")  # Remove redundant ylabel on the right plot\n",
    "axes[1].grid(axis = 'x', linestyle = '--', alpha = 0.7)\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a833d19-2288-464a-8ae5-a2415d9612de",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.em; padding: 15px; margin: 10px 0; text-align: left; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "\n",
    "    While the ranking is similar, the scales differ because the two methods measure importance in different ways:\n",
    "    \n",
    "    ⦾ Random Forest Feature Importance \n",
    "       - Calculated based on the reduction in impurity (e.g. the MSE) that each feature provides when used for splits.\n",
    "       - Normalized (0 - 1), so they represent the relative importance of features in splitting decisions.\n",
    "       - Rankings are more about the model's inner workings:\n",
    "       - i.e.: how frequently and effectively features are used to split nodes and reduce error during model training.\n",
    "        \n",
    "    ⦾ SHAP Mean Absolute Values\n",
    "       - Computed per sample as the contribution each feature makes to the model’s prediction, then averaged across all samples.\n",
    "       - Values are in the same units as the output variable (SST), and are not normalised in the same way as RF.\n",
    "       - More about the actual impact of feature values:\n",
    "       - i.e.: how much each feature’s actual value contributed to the prediction (game theory foundation).\n",
    "<div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
