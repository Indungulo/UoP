{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dca23171-0e41-41ca-a2d3-3def8cb2cd66",
   "metadata": {},
   "source": [
    "Authors: L. Biermann (UoP)\n",
    "Credits: This code was originally developed for the MaRS Modules.\n",
    "License: This code is offered as free-to-use in the public domain, with no warranty.\n",
    "Date_V2: 25/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb9eb-2368-460a-9c90-cd738bbfc23c",
   "metadata": {},
   "source": [
    "# Shallow Machine Learning Models: Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be4359-7113-44df-9db4-33eefaa5d8bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.1em; padding: 10px; margin: 10px 0; text-align: center;\">\n",
    "    \n",
    "    Multivariate regression models the relationship between one dependent variable and two or more independent variables using a linear equation.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395d4ad-9eff-4dba-9ac7-c07b9dc4d6a8",
   "metadata": {},
   "source": [
    "### Import Libraries including from `sklearn` for shallow ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff73e0-8237-4087-81ba-8e4e3bb4e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learn\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Data Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignorewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7afd-8af2-44ea-9afe-5c2861b63ecc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Data Preprocessing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560a835-a995-4b9b-af90-8f954b37c4a9",
   "metadata": {},
   "source": [
    "### Option 1 to Load CSV files containing variables -- pandas' `read_csv function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fa81a-211a-48ff-ba71-bc709239ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are imported in Dataframe format\n",
    "SSH = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSH.csv\", comment='#') # tells pandas to ignore lines starting with '#'\n",
    "SST = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SST.csv\", comment='#')\n",
    "SSS = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_SSs.csv\", comment='#')\n",
    "VEL = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_VEL.csv\", comment='#')\n",
    "MLD = pd.read_csv(\"cmems_mod_glo_phy_my_0.083deg_P1D-m_MLD.csv\", comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67e03a-dad7-41e3-9de3-6e5c17a3bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UTC format that our dates (times) are currently in:\n",
    "SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "\n",
    "# Step1: convert to a more friendly format, add 'dates' as new column \n",
    "SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Step2: Remove the times in this case as they contain no real information\n",
    "SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "# Step3: Drop the now unnecessary 'time' column\n",
    "SSH = SSH.drop(columns=['time'])\n",
    "\n",
    "# Re-order your columns so date is still first\n",
    "SSH = SSH[['dates','zos']]\n",
    "# Display\n",
    "print(SSH.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50eacc-7968-49b8-869a-b5c0c113f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now combine these different vars to make a new df\n",
    "df = pd.DataFrame({'Date':SSH['dates'], 'SSH':SSH['zos'], 'SST':SST['thetao'], 'SSS':SSS['so'], \n",
    "                   'Vuo':VEL['uo'], 'Vvo':VEL['vo'], 'MLD':MLD['mlotst']})\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdadede-b0f2-4bca-a587-aa10e18980fc",
   "metadata": {},
   "source": [
    "### Option 2 to Load CSV files containing variables -- `glob` and pandas' `read_csv function`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e71a1b77-92e6-4232-96a0-12c53c2a4550",
   "metadata": {},
   "source": [
    "Though more complicated, it is an easier way to load data if you have loads of files/ filenames change routinely"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92e43d2-5573-4e10-bcc5-0af5c9da5266",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the file pattern to match relevant CSV files\n",
    "file_pattern = \"cmems_mod_glo_phy_my_0.083deg_P1D-m_*.csv\"\n",
    "\n",
    "# Read all matching CSV files into a dictionary\n",
    "df_dict = {}\n",
    "for file in glob.glob(file_pattern):\n",
    "    var_name = file.split(\"_\")[-1].split(\".\")[0]  # Extract variable name from filename\n",
    "    df_dict[var_name] = pd.read_csv(file, comment='#')\n",
    "\n",
    "# Ensure SSH is processed correctly (dates + renaming 'zos' to 'SSH')\n",
    "SSH = df_dict.get(\"SSH\")\n",
    "if SSH is not None:\n",
    "    SSH['dates'] = pd.to_datetime(SSH['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "    SSH['dates'] = SSH['dates'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    SSH['dates'] = pd.to_datetime(SSH['dates'])\n",
    "    SSH = SSH.drop(columns=['time'])\n",
    "    SSH = SSH.rename(columns={'zos': 'SSH'})  # Rename 'zos' to 'SSH'\n",
    "    SSH = SSH[['dates', 'SSH']]  # Keep 'dates' and SSH variable\n",
    "\n",
    "# Mapping of expected variables to their corresponding column names in CSVs\n",
    "data_vars = {\n",
    "    \"SST\": \"thetao\",\n",
    "    \"SSS\": \"so\",\n",
    "    \"Vuo\": \"uo\",\n",
    "    \"Vvo\": \"vo\",\n",
    "    \"MLD\": \"mlotst\"}\n",
    "\n",
    "# Merge all datasets dynamically\n",
    "df = SSH.copy() if SSH is not None else pd.DataFrame()\n",
    "\n",
    "for key, col in data_vars.items():\n",
    "    dataset_key = \"VEL\" if key in [\"Vuo\", \"Vvo\"] else key  # Ensure velocity data is accessed correctly\n",
    "    if dataset_key in df_dict:\n",
    "        df[key] = df_dict[dataset_key][col].values  # Assign values from each dataset\n",
    "\n",
    "# Print the first few rows to verify the result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee1a7b-6f4b-4688-856e-d95cdd0b726a",
   "metadata": {},
   "source": [
    "### Set the `predictor` and `target` variables (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786007cb-4a98-495d-a374-2d1b0e3f9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['SSH', 'SSS', 'Vuo', 'Vvo', 'MLD'] # Predictor vars\n",
    "X = df[predictors].values \n",
    "y = df['SST'].values      # Target variable\n",
    "# Needs to be (n,n)(n,)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42294e7-ec41-4844-ae43-df3800780f12",
   "metadata": {},
   "source": [
    "### Split the data into two sets: `training` (80%) and `test` (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916045c-ba64-4fb2-a1a3-39c085fc725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your dataset so 20% is set aside for testing (0.2) \n",
    "# Set random_state to ensure yr train-test split is always the same (for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the 80% training: 20% testing split\n",
    "print(\"Trainin set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\",  X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b02411-1c1d-4046-a946-c67ec4de1c43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    \n",
    "    Elastic Net Regularisation\n",
    "<div>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e29ecf58-4f9a-4350-ab10-4f58c0aa7315",
   "metadata": {},
   "source": [
    "Hyperparameters are values set `before training` that control how the model learns. \n",
    "-----------------------------------------------------------------------------------\n",
    "In this case:\n",
    "-- l1_ratio controls the balance between Lasso (L1) and Ridge (L2).\n",
    "-- alpha controls the regularization strength.\n",
    "-- ElasticNetCV automatically searches for the best combination of these hyperparameters using cross-validation (cv=5).\n",
    "\n",
    "Now when the model runs, it will:\n",
    "---------------------------------\n",
    "1. Test different values of l1_ratio (0.1, 0.5, 0.9).\n",
    "2. Iterate over 100 different values of alpha (np.logspace(-3, 1, 100)).\n",
    "3. Split the dataset into 5 parts  \n",
    "        -> train on 4 parts and validate on 1 part.\n",
    "        -> repeat 5x so every part gets used for validation.\n",
    "4. Select the best combination that maximizes performance (e.g., highest R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a875b-b87b-43f2-a4b4-58f80998b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Elastic Net with cross-validation\n",
    "elastic_net = ElasticNetCV(l1_ratio = [0.1, 0.5, 0.9],         # Mix of Lasso (L1) & Ridge (L2)\n",
    "                           alphas = np.logspace(-3, 1, 100),   # Range of regularization strengths\n",
    "                           cv = 5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f90075-4123-4843-98c2-bb8103de40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on the training set\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict SST on the test dataset\n",
    "y_pred = elastic_net.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e04ae2-d25a-4dc5-9f74-8b88e466fea3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Evaluating Model Performance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a9b1b-a97b-4794-8832-dfb9f6d3e2a3",
   "metadata": {},
   "source": [
    "### Metrics for Multivariate Regression Model: `R2` and `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c6c37-b951-43ef-be20-98d5c5a27d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "split_score = elastic_net.score(X_test, y_test)\n",
    "\n",
    "# Compute R-squared value\n",
    "r_sqd = elastic_net.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Multivar Elastic Net R²:   {:.2}\".format(r_sqd))\n",
    "print(\"Multivar Elastic Net RMSE: {:.2f}\".format(rmse))\n",
    "# print(\"Score:{:.2}\".format(split_score))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "727a6e44-cfa8-4657-8a86-27c366af4cd0",
   "metadata": {},
   "source": [
    "Linear Regression R²:   0.28\n",
    "Linear Regression RMSE: 1.62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f0c44-b69f-4913-b7d8-994056b5d8ef",
   "metadata": {},
   "source": [
    "### Those are better scores! But which of the additional variable/s (feature/s) have contributed to this improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d7990-09f2-4af5-bc74-27004fa6bd4e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.8em; font-weight: bold; padding: 15px; margin: 10px 0; text-align: center; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "    Feature Importance\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcf74d-6e09-44c7-9bfe-48f1fd1776e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances:\n",
    "feature_importance = pd.Series(elastic_net.coef_, index = predictors)\n",
    "\n",
    "# Sort df so most important variables are at the top (descending order)\n",
    "regress_df = feature_importance.sort_values(ascending= False)\n",
    "print('Feature Importance:\\n',regress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de01517-2fd4-4f45-b32f-cd4dbee82be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance:\n",
    "fig2 = plt.figure(figsize = (6, 4))\n",
    "\n",
    "# Use diverging palette from Seaborn\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "# Create a barplot with the Spectral color palette\n",
    "sns.barplot(x = regress_df.values, y = regress_df.index, \n",
    "            palette = cmap(regress_df.rank(pct = True)))\n",
    "\n",
    "# Add features and labels\n",
    "plt.title(\"Feature Importance (Elastic Net Coefficients)\", fontweight='bold')\n",
    "plt.xlabel(\"Coefficient Value\", fontsize = 10)\n",
    "plt.ylabel(\"Features\", fontsize = 10)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6e752-f930-4260-bd75-571c48818923",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" \n",
    "     style=\"font-size: 1.em; padding: 15px; margin: 10px 0; text-align: left; background-color: #d9edf7; border-color: #bce8f1; color: #31708f; border-radius: 8px;\">\n",
    "\n",
    "    ⦾ SSH appears to be the dominant predictor with the highest Elastic Net coefficient.\n",
    "    \n",
    "    ⦾ However, we must remember that ElasticNet applies both L1 and L2 penalties, which shrinks all coefficients. \n",
    "       - Good: this regularisation reduces overfitting.\n",
    "       - Less good: other predictors can appear less important — even if they contribute, and especially when they're correlated.\n",
    "        \n",
    "    ⦾ Correlated predictors tend to share predictive power, so the penalty may disproportionately reduce their individual \n",
    "      coefficients, making it seem like they have little value in the ranking.\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033622c-2be7-460a-8081-deb241240ab6",
   "metadata": {},
   "source": [
    "### Ultimately, we've likely reached the limit of what linear models can do for us. If we're dealing with `non-linearity`... we need to upgrade to a model that can account for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fca337-7c6a-4d38-983c-fb8584ab09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 1 row and 2 columns of subplots\n",
    "fig3, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# ---------------------------\n",
    "# Scatterplot: SSH vs. SST\n",
    "ax1.scatter(df['SSH'], df['SST'], color='purple', alpha=0.7, marker='.', s=10)\n",
    "ax1.set_xlabel('SSH')                           # Label for the x-axis\n",
    "ax1.set_ylabel('SST')                           # Label for the y-axis\n",
    "ax1.set_title('SSH vs. SST' , weight='bold')    # Title for this subplot\n",
    "ax1.grid(True, linestyle=':', linewidth=0.5)    # Add a dotted grid for clarity\n",
    "\n",
    "# ---------------------------\n",
    "# Scatterplot: SSS vs. SST\n",
    "ax2.scatter(df['SSS'], df['SST'], color='orange', alpha=0.7, marker='.', s=10)\n",
    "ax2.set_xlabel('SSS')                           # Label for the x-axis\n",
    "ax2.set_ylabel('SST')                           # Label for the y-axis\n",
    "ax2.set_xlim([35.3, 36.7])\n",
    "ax2.set_title('SSS vs. SST' , weight='bold')    # Title for this subplot\n",
    "ax2.grid(True, linestyle=':', linewidth=0.5)    # Add a dotted grid for clarity\n",
    "\n",
    "# ---------------------------\n",
    "# Scatterplot: MLD vs. SST\n",
    "ax3.scatter(df['MLD'], df['SST'], color='teal', alpha=0.7, marker='.', s=10)\n",
    "ax3.set_xlabel('MLD')                           # Label for the x-axis\n",
    "ax3.set_ylabel('SST')                           # Label for the y-axis\n",
    "ax3.set_xlim([10, 100])\n",
    "ax3.set_title('MLD vs. SST' , weight='bold')    # Title for this subplot\n",
    "ax3.grid(True, linestyle=':', linewidth=0.5)    # Add a dotted grid for clarity\n",
    "\n",
    "# Adjust layout to prevent overlapping elements\n",
    "plt.tight_layout()\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc63b23f-5fa9-4abc-a2b0-bc2d24520de9",
   "metadata": {},
   "source": [
    "Did you know -- in oceanography and atmospheric sciences, velocity is represented using two orthogonal (perpendicular) components:\n",
    "\n",
    "U-velocity (uo): The zonal (east-west) component of velocity.\n",
    "----------------\n",
    "Positive U → Flow towards the east (i.e., moving in the direction of increasing longitude).\n",
    "Negative U → Flow towards the west (i.e., moving in the direction of decreasing longitude).\n",
    "\n",
    "V-velocity (vo): The meridional (north-south) component of velocity.\n",
    "----------------\n",
    "Positive V → Flow towards the north (i.e., moving in the direction of increasing latitude).\n",
    "Negative V → Flow towards the south (i.e., moving in the direction of decreasing latitude)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
